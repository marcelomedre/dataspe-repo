fileUrl3 <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
BaltimoreRestaurants <- xmlTreeParse(fileUrl3, useInternal = TRUE)
rootNode(BaltimoreRestaurants)
rootNode <- xmlRoot(BaltimoreRestaurants)
rootNode
rootNode(BaltimoreRestaurants)
xmlName(rootNode)
zipcode <- xmlSApply(rootNode, "//zipcode" xmlValue)
zipcode <- xmlSApply(rootNode, "//zipcode", xmlValue)
zipcode <- xpathSApply(rootNode, "//zipcode", xmlValue)
length(zipcode[zipcode == 21231])
library(data.table)
fileUrl4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url=fileUrl4, destfile="Housing_Idaho.csv", mode="w", method="curl")
download.file(url=fileUrl4, destfile="Housing_Idaho.csv", mode="wb", method="curl")
download.file(fileUrl4, destfile="./data/Housing_Idaho.csv", method="auto")
?fread
DT <- fread(input = "Housing_Idaho.csv", sep = ",")
DT <- fread(input = "./data/Housing_Idaho.csv", sep = ",")
pwgtp15 <- system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
pwgtp15 <- system.time(mean(DT[DT$SEX==1,]$pwgtp15)
pwgtp15 <- system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(DT[,mean(pwgtp15)], by = SEX)
system.time(DT[,mean(pwgtp15), by = SEX])
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.timemean(DT$pwgtp15,by=DT$SEX))
system.timemean(DT$pwgtp15,by=DT$SEX)
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(rowMeans(DT)[DT$SEX==1])
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
0.3/100
3453*0.003
2656*0.003
111/6
library(swirl)
packageVersion(swirl)
packageVersion("swirl")
install_from_swirl("Getting and Cleaning Data")
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(mean(by_package))
?summarize
summarize(by_package, mean(size))
?n
?n_unique
?n_distinct
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum[pack_sum$count > 679])
?filter
?filter()
top_counts <- filter(pack_sum, count > 679])
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
?arrange
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs probs = 0.99)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
arrange(top_unique, unique)
arrange(top_unique, desc(unique)
)
arrange(top_unique, desc(unique))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
aubmit()
submit()
submit()
submit()
View(result3)
submit
submit()
submit
submit()
submit()
?mutate
submit()
submit()
submit()
submit()
submit()
submit()
1.007
1.007/70000
ans <- 1.07/70000
ans*20
1.07*20
21.4/70000
0.0003*100
install.packages("RMySQL", type = "source")
library(RMySQL)
ucscDb <- dbConnect(MySQL(), user = "genome",
host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "Show databases;"); dbDisconnect(ucscDb)
result
hg19 <- dbConnect(MySQL(), user = "genome", db = "hg19",
host = "genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affData <- dbReadTable(hg19, "affyU133Plus2")
head(affData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where mismatches between 1 and 3")
affMis <- fetch(query); quantile(affMis$misMatches)
affMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affMisSmall)
dbDisconnect(hg19)
library(httr)
require(httpuv)
install.packages("httpuv")
require(httpuv)
oauth_endpoints("github")
myapp <- oauth_app("quiz2",
key = "7bb89f22156737b7958a",
secret = "2f8db11bd573309cac5c0435c75d0a80a6c0ccd8")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
repo_list <- content(req)
repo_list
library(jsonlite)
json1 = repo_list
json2 = jsonlite::fromJSON(toJSON(json1))
View(json2)
View(json2)
View(json2)
xpathSApply(repo_list, "//datasharing", xmlValue)
repo <- c()
for (i in length(repo_list)){
repo <- repo_list[i]
if (repo$name == "datasharing"){
our_repo = repo
break
}
}
repo_list
head(repo_list)
list(repo_list$names, repo_list$created_at)
repo <- c()
for (i in length(repo_list)){
repo <- repo_list[i]
if (repo$name == "datasharing"){
our_repo = repo
break
}
}
for (i in 1:length(repo_list)){
repo <- repo_list[i]
if (repo$name == "datasharing"){
our_repo = repo
break
}
}
answer1 <- c()
for (i in 1:length(repo_list)) {
repo <- repo_list[[i]]
if (repo$name == "datasharing") {
answer1 = repo
break
}
}
if (length(answer1) == 0) {
msg("No such repository found: 'datasharing'")
} else {
msg("The repository 'datasharing' was created at", answer1$created_at)
}
repo <- c()
for (i in 1:length(repo_list)){
repo <- repo_list[[i]]
if (repo$name == "datasharing"){
our_repo = repo
break
}
}
our_repo
?msg
?message
if(length(our_repo) == 0){
message("No such repository found :'datasharing'")
}else {
message("The repository 'datasharing' was created at", our_repo$created_at)
}
install.packages("sqldf")
library(sqldf)
library(RMySQL)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url, destfile = "acs.csv", method = "auto")
survey <- read.csv("acs.csv")
survey <- read.csv("acs.csv", header = TRUE)
head(survey)
sqldf("Select pwgtp1 from acs where AGEP < 50")
acs <- read.csv("acs.csv", header = TRUE)
query 1 <- sqldf("Select pwgtp1 from acs where AGEP < 50")
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50")
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", acs)
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "acs")
acs <- read.csv("acs.csv", sep =  ",", header = TRUE)
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "acs")
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50")
?sqldf
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "RMySQL")
View(acs)
sqldf("Select pwgtp1 from acs where AGEP < 50")
fname <- "survey.csv"
download_if_not_exists(fname, "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
download.file(fname, "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
acs <- read.csv("acs.csv", header = TRUE, sep = ",")
answer2 <- sqldf("select pwgtp1 from acs where AGEP < 50")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
f <- file.path(getwd(), "ss06pid.csv")
download.file(url, f)
acs <- data.table(read.csv(f))
acs <- read.csv(f)
query1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
library(RMySQL)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url, destfile = "acs.csv", method = "auto")
acs <- read.csv("acs.csv", sep =  ",", header = TRUE)
sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "SQLite")
query1 <- sqldf("Select pwgtp1 from acs where AGEP < 50", drv = "SQLite")
View(query1)
query2 <- sqldf("select pwgtp1 from acs", drv = "SQLite")
query3 <- sqldf("select * from acs where AGEP < 50", drv = "SQLite")
query4 <- sqldf("select * from acs", drv = "SQLite")
View(query2)
View(query3)
answer <- unique(acs$AGEP)
answer <- unique(acs$AGEP)
?identical
query1 <- sqldf("select unique AGEP from acs", drv = "SQLite")
query2 <- sqldf("select distinct AGEP from acs", drv = "SQLite")
query3 <- sqldf("select AGEP where unique from acs", drv = "SQLite")
query4 <- sqldf("select distinct pwgtp1 from acs", drv = "SQLite")
identical(answer, query1)
identical(answer, query2)
identical(answer, query3)
identical(answer, query4)
query1 <- sqldf("select unique AGEP from acs")
View(query2)
library(XML)
library(httr)
?nchar
library(XML)
library(httr)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
html <- readLines(con)
close(con)
answer <- c(nchar(html[10]), nchar(html[20]), nchar(html[30]), nchar(html[100]))
answer
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(url, destfile = "data.for", method = "auto")
data <- read.fwf(data.for)
?read.fwf
lines <- readLines(url, n=10)
widths <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler",
"sstaNino12", "filler", "sstNino3", "filler", "sstaNino3",
"filler", "sstNino34", "filler", "sstaNino34", "filler",
"sstNino4", "filler", "sstaNino4")
data <- read.fwf(data.for, widths = widths, header = FALSE, skip = 4, col.names = colNames)
data <- read.fwf(url, widths = widths, header = FALSE, skip = 4, col.names = colNames)
data <- read.fwf("data.for", widths = widths, header = FALSE, skip = 4, col.names = colNames)
View(data)
answer <- sum(data[,4])
answer
View(data)
data <- read.fwf("data.for", widths = widths, header = FALSE, col.names = colNames)
View(data)
data <- read.fwf("data.for", widths = widths, header = FALSE, skip = 4, col.names = colNames)
?grep
d <- d[, grep("^[^filler]", names(d))]
d <- d[, grep("^[^filler]", names(data))]
data <- data[, grep("^[^filler]", names(data))]
sum(d[, 4])
sum(data[, 4])
View(data)
answer <- sum(data[,4])
answer
86.83*3
[0-9]+ (.*)[0-9]+
## Working with dates
d1 = date()
d1
class(d1)
s2 = Sys.Date()
class(d2)
d2 = Sys.Date()
class(d2)
format(d2, "%a" "%b" %c"")
format(d2, "%a "%b %c")
format(d2, "%a "%b %d")
format(d2, "%a "%b %d")
format(d2, "%a "%b %y")
format(d2, "%a "%b %y")
format(d2, "%a "%b %y")
x=c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z= as.Date(x, "%d%b%Y")
z
z[1]-z[2]
as.numeric(z[1-z[4]])
as.numeric(z[1]-z[4]])
as.numeric(z[1]-z[2]])
as.numeric(z[1]-z[2])
as.numeric(z[1]-z[4])
weedays(d2)
weekdays(d2)
months(d2)
julian(d2)
install.packages("lubridate")
library(lubridate)
ymd("20140108")
mdy("08/08/2015")
dmy("14/08/1988")
ymd_hms("14/08/1988 10:15:33")
ymd_hms("14-08-1988 10:15:33")
ymd_hms("2014-08-19 10:15:33")
ymd_hms("2014-08-19 10:15:33", tz = "Pacific/Auckland")
x=dmy(c("1jan1960", "2jan1960", "31mar1960", "30jul1960"))
wday(x[1])
wday(x[1], label = TRUE)
library(dplyr)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
if(file.exists("./data")){dir.create("./data")}
download.file(fileUrl, destfile = ".data/idaho_survey.csv", method = "auto")
download.file(fileUrl, destfile = ".idaho_survey.csv", method = "auto")
library(data.table)
getwd()
dataIdaho <- data.table(read.csv("idaho_survey.csv", stringsAsFactors = FALSE)
dataIdaho <- data.table(read.csv("idaho_survey.csv", stringsAsFactors = FALSE))
View(dataIdaho)
?strsplit
names(dataIdaho)
names <- names(dataIdaho)
strsplit(names, "wgtp")
strsplit(names, wgtp)
splittedData <- strsplit(names, "wgtp")
splittedData[123]
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl2, destfile = "GDP.csv", method = "auto")
dataGDP <- data.table(read.csv("GDP.csv", stringsAsFactors = FALSE))
View(dataGDP)
dataGDP <- data.table(read.csv("GDP.csv", skip = 4, stringsAsFactors = FALSE))
select(dataGDP, c("X", "X1", "X3", "X4"))
select(dataGDP, c(1, 2, 4, 5))
dataGDP <- select(dataGDP, c(1, 2, 4, 5))
?colnames
colnames(dataGDP) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP)
dataGDP$numGDP <- as.numeric(gsub(",","",dataGDP$GDP))
dataGDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE))
dataGDP <- select(dataGDP, c(1, 2, 4, 5))
colnames(dataGDP) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP)
dataGDP$numGDP <- as.numeric(gsub(",","",dataGDP$GDP))
average <- mean(dataGDP$numGDP)
average
?grep
grep("United$",Country), 3
grep("United$",Country)
grep("United$", dataGDP$Country)
grep("*United$", dataGDP$Country)
grep("^United",dataGDP$Country)
grep("^United",dataGDP$Country)
length(grep("United$", dataGDP$Country))
length(grep("*United$", dataGDP$Country))
length(grep("^United",dataGDP$Country))
length(grep("^United",dataGDP$Country))
fileUrl3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl3, destfile = "GDP_2.csv", method = "auto")
fileUrl4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl4, destfile = "Educ.csv", method = "auto")
fileUrl3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl3, destfile = "GDP_2.csv", method = "auto")
fileUrl4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl4, destfile = "Educ.csv", method = "auto")
dataGDP2 <- data.table(read.csv("GDP.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE))
dataGDP2 <- select(dataGDP2, c(1, 2, 4, 5))
colnames(dataGDP2) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP2)
dataEduc <- data.table(read.csv("Educ.csv", stringsAsFactors = FALSE))
View(dataEduc)
View(dataGDP)
View(dataEduc)
View(dataGDP2)
View(dataEduc)
?merge
dataEduc <- dataEduc[,c("CountryCode", "Special.Notes")]
fullData <- merge(dataGDP2,dataEduc, by.x = CountryCode, by.y = CountryCode)
fullData <- merge(dataGDP2,dataEduc, by.x = "CountryCode", by.y = "CountryCode")
View(fullData)
mergedData <- merge(dataGDP2,dataEduc, by.x = "CountryCode", by.y = "CountryCode")
?grep
?grpl
?grepl
length(grep("[Ff]iscal year end(*/)+ June" ), mergedData$Special.Notes)
length(grep("[Ff]iscal year end(*/)+ June", mergedData$Special.Notes))
length(grep("[Ff]iscal year (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year end: (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year end:(*/)+June", mergedData$Special.Notes))
length(grepl("^[Ff]iscal year end:(*/)+June", mergedData$Special.Notes))
View(mergedData)
mergedData$Special.Notes[grepl("^Fiscal year end: June 30", mergedData$Special.Notes)]
length(grep("^Fiscal year end: June 30", mergedData$Special.Notes))
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes <- data.table(sampleTimes)
View(sampleTimes)
?POSIXlt
?grep
sampleTimes12 <- grep("^2012", sampleTimes)
sampleTimes12 <- sampleTimes[grep("^2012", sampleTimes)]
View(sampleTimes12)
?wday
sapply(sampleTimes12, wday)
sampleTimes12Mon <- sapply(sampleTimes12, wday)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday))
View(sampleTimes12Mon)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(..., label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(... , label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday))
wday(sampleTimes12Mon, label = TRUE)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, weekdays))
View(sampleTimes12Mon)
?n
MOndays <- length(sampleTimes12Mon[grepl("segunda-feira", sampleTimes12Mon)])
MOndays
length(sampleTimes12Mon[grepl("segunda-feira", sampleTimes12Mon$sampleTimes)])
length(sampleTimes12Mon[grep("segunda-feira", sampleTimes12Mon$sampleTimes)])
length(sampleTimes12Mon(grep("segunda-feira", sampleTimes12Mon$sampleTimes)))
sampleTimes12Mon(grep("segunda-feira", sampleTimes12Mon$sampleTimes))
length(which(wday(sampleTimes12Mon, label = T) == "segunda-feira"))
length(which(sampleTimes12Mon$sampleTimes == "segunda-feira"))
Mondays <- length(which(sampleTimes12Mon$sampleTimes == "segunda-feira"))
Mondays
getwd()
setwd("C:/Users/Marcelo/Desktop/Coursera/Project/dataspe-repo")
library(dplyr)
library(data.table)
x_train <- read.table("./data/Project/UCI HAR Dataset/train/X_train.txt") #import X_train data
y_train <- read.table("./data/Project/UCI HAR Dataset/train/y_train.txt") #import y_train data
subjecttrain <- read.table("./data/Project/UCI HAR Dataset/train/subject_train.txt") #import subject_train data
x_test <- read.table("./data/Project/UCI HAR Dataset/test/X_test.txt") #import X_test data
y_test <- read.table("./data/Project/UCI HAR Dataset/test/y_test.txt") #import y_test data
subjecttest <- read.table("./data/Project/UCI HAR Dataset/test/subject_test.txt") #import subject_test data
features <- read.table("./data/Project/UCI HAR Dataset/features.txt")
activityLabels <-read.table("./data/Project/UCI HAR Dataset/activity_labels.txt")
colnames(x_train) <- features[,2]
colnames(y_train) <- "activityId"
colnames(subjecttrain) <- "subjectId"
colnames(x_test) <- features[,2]
colnames(y_test) <- "activityId"
colnames(subjecttest) <- "subjectId"
colnames(activityLabels) <- c("activityId", "activityType")
dataTrain <- cbind(subjecttrain,y_train,x_train)
dataTest <- cbind(subjecttest,y_test,x_test)
fullData <- rbind(dataTrain,dataTest)
colnames <- colnames(fullData)
meanStd <- (grepl("subjectId", colnames)|
grepl("activityId", colnames)|
grepl(".*mean.*", colnames)|
grepl(".*std.*", colnames)
)
meanStdData <- fullData[,meanStd]
FinalData <- merge(meanStdData,activityLabels, by = "activityId",
all.x = TRUE)
names(FinalData)
colNames2 = gsub("[-()]", " ",colNames2)
colNames2 = gsub("std","StdDev",colNames2)
colnames2 <- colnames(FinalData)
colNames2 = gsub("[-()]", " ",colNames2)
colnames2 <- colnames(FinalData)
colNames2 = gsub("[-()]", " ",colNames2)
colNames2 <- colnames(FinalData)
colNames2 = gsub("[-()]", " ",colNames2)
colNames2 = gsub("std","StdDev",colNames2)
colNames2 = gsub("mean","Mean",colNames2)
colNames2 = gsub("^(t)","time",colNames2)
colNames2 = gsub("^(f)","freq",colNames2)
colNames2 = gsub("([Gg]ravity)","Gravity",colNames2)
colNames2 = gsub("([Bb]ody[Bb]ody|[Bb]ody)","Body",colNames2)
colNames2 = gsub("[Gg]yro","Gyroscope",colNames2)
colNames2 = gsub("Mag","Magnitude",colNames2)
colNames2 = gsub("Acc","Accelerometer",colNames2)
colnames(FinalData) = colNames2
View(FinalData)
newTidyData <- aggregate( .~ subjectId + activityType, FinalData, mean)
newTidyData <- newTidyData[order(newTidyData$subjectId),]
write.table(newTidyData, file = "./data/tidydata.csv", row.names = TRUE,
sep = ",")
newTidyData <- aggregate( .~ subjectId + activityType, FinalData, mean)
newTidyData <- newTidyData[order(newTidyData$subjectId),]
write.table(newTidyData, file = "./data/newTidyData.csv", row.names = TRUE,
sep = ",")
